{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\AMC\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "import rbflayer, kmeans_initializer\n",
    "from rbflayer import InitCentersRandom\n",
    "from keras.initializers import RandomUniform, Initializer, Constant\n",
    "\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Activation, Dropout\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from scipy import * \n",
    "from scipy.linalg import norm, pinv\n",
    "from matplotlib import pyplot as plt  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "    # Documentation is available online on Github at the address below.\n",
    "    # From: https://github.com/philipperemy/keras-visualize-activations\n",
    "    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "    funcs = [K.function([inp] + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations\n",
    " \n",
    " \n",
    "def get_data(n, input_dim, attention_column=1):\n",
    "    \"\"\"\n",
    "    Data generation. x is purely random except that it's first value equals the target y.\n",
    "    In practice, the network should learn that the target = x[attention_column].\n",
    "    Therefore, most of its attention should be focused on the value addressed by attention_column.\n",
    "    :param n: the number of samples to retrieve.\n",
    "    :param input_dim: the number of dimensions of each element in the series.\n",
    "    :param attention_column: the column linked to the target. Everything else is purely random.\n",
    "    :return: x: model inputs, y: model targets\n",
    "    \"\"\"\n",
    "    x = np.random.standard_normal(size=(n, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column] = y[:, 0]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "#from attention_utils import get_activations, get_data\n",
    " \n",
    "np.random.seed(1337)  # for reproducibility\n",
    " \n",
    "from keras.models import *\n",
    "from keras.layers import Input, Dense,Multiply,Activation\n",
    " \n",
    "input_dim = 4\n",
    " \n",
    " \n",
    " \n",
    "def Att(att_dim,inputs,name):\n",
    "    V = inputs\n",
    "    QK = Dense(att_dim,use_bias=None)(inputs)\n",
    "    QK = Activation(\"softmax\",name=name)(QK)\n",
    "    MV = Multiply()([V, QK])\n",
    "    return(MV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = Input(shape=(input_dim,))\n",
    " \n",
    "    atts1 = Att(input_dim,inputs,\"attention_vec\")\n",
    " \n",
    "    x = Dense(16)(atts1)\n",
    "    atts2 = Att(16,x,\"attention_vec1\")\n",
    " \n",
    " \n",
    "    output = Dense(1, activation='sigmoid')(atts2)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05427413  1.         -1.73300358 -2.34836064]\n",
      " [ 0.11045848  1.         -0.21589959 -0.52714519]] [[1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "inputs_1, outputs = get_data(N, input_dim)\n",
    "\n",
    "print(inputs_1[:2],outputs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 4), (10000, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_1.shape,outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05427413,  1.        , -1.73300358, -2.34836064],\n",
       "       [ 0.11045848,  1.        , -0.21589959, -0.52714519],\n",
       "       [-1.62608443,  0.        , -1.06804895,  0.9379454 ],\n",
       "       ...,\n",
       "       [-0.33466576,  1.        ,  1.22777748,  1.70883121],\n",
       "       [ 0.19871098,  1.        , -0.50357535, -0.55081286],\n",
       "       [-0.68933405,  0.        ,  0.28214771,  0.66918172]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27979466  1.          0.26975574 -1.35149786]\n",
      " [-1.73264006  1.          0.91832546  0.94513606]] [[1]\n",
      " [1]]\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 4)            16          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Activation)      (None, 4)            0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 4)            0           input_7[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 16)           80          multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 16)           256         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec1 (Activation)     (None, 16)           0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 16)           0           dense_21[0][0]                   \n",
      "                                                                 attention_vec1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            17          multiply_11[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "6400/8000 [=======================>......] - ETA: 0s - loss: 0.6910 - acc: 0.5502WARNING:tensorflow:From D:\\Anaconda3\\envs\\AMC\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "8000/8000 [==============================] - 0s 25us/sample - loss: 0.6905 - acc: 0.5594 - val_loss: 0.6883 - val_acc: 0.5730\n",
      "Epoch 2/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6850 - acc: 0.5861 - val_loss: 0.6803 - val_acc: 0.5765\n",
      "Epoch 3/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.6743 - acc: 0.5829 - val_loss: 0.6665 - val_acc: 0.5870\n",
      "Epoch 4/20\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6572 - acc: 0.6149 - val_loss: 0.6456 - val_acc: 0.6350\n",
      "Epoch 5/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6298 - acc: 0.6643 - val_loss: 0.6116 - val_acc: 0.7035\n",
      "Epoch 6/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5859 - acc: 0.7545 - val_loss: 0.5537 - val_acc: 0.8060\n",
      "Epoch 7/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5143 - acc: 0.8414 - val_loss: 0.4688 - val_acc: 0.8650\n",
      "Epoch 8/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.4350 - acc: 0.8712 - val_loss: 0.3983 - val_acc: 0.8825\n",
      "Epoch 9/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.3722 - acc: 0.8896 - val_loss: 0.3435 - val_acc: 0.8975\n",
      "Epoch 10/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.3215 - acc: 0.9095 - val_loss: 0.2983 - val_acc: 0.9140\n",
      "Epoch 11/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2778 - acc: 0.9275 - val_loss: 0.2580 - val_acc: 0.9275\n",
      "Epoch 12/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2368 - acc: 0.9450 - val_loss: 0.2166 - val_acc: 0.9530\n",
      "Epoch 13/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1947 - acc: 0.9589 - val_loss: 0.1748 - val_acc: 0.9645\n",
      "Epoch 14/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.1515 - acc: 0.9755 - val_loss: 0.1312 - val_acc: 0.9800\n",
      "Epoch 15/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1114 - acc: 0.9865 - val_loss: 0.0940 - val_acc: 0.9905\n",
      "Epoch 16/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.0807 - acc: 0.9952 - val_loss: 0.0688 - val_acc: 0.9975\n",
      "Epoch 17/20\n",
      "8000/8000 [==============================] - 0s 18us/sample - loss: 0.0608 - acc: 0.9987 - val_loss: 0.0533 - val_acc: 0.9985\n",
      "Epoch 18/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.0483 - acc: 0.9995 - val_loss: 0.0433 - val_acc: 0.9995\n",
      "Epoch 19/20\n",
      "8000/8000 [==============================] - 0s 19us/sample - loss: 0.0397 - acc: 0.9999 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.0335 - acc: 0.9999 - val_loss: 0.0307 - val_acc: 1.0000\n",
      "----- activations -----\n",
      "(1, 4)\n",
      "attention = [0.2425457  0.36885247 0.24522386 0.14337792]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = build_model()\n",
    "m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(m.summary())\n",
    "\n",
    "m.fit(inputs_1, outputs, epochs=20, batch_size=128, validation_split=0.2)\n",
    "\n",
    "testing_inputs_1, testing_outputs = get_data(1, input_dim)\n",
    "\n",
    "# Attention vector corresponds to the second matrix.\n",
    "# The first one is the Inputs output.\n",
    "attention_vector = get_activations(m, testing_inputs_1,\n",
    "                                   print_shape_only=True,\n",
    "                                   layer_name='attention_vec')[0].flatten()\n",
    "print('attention =', attention_vector)\n",
    "\n",
    "# plot part.\n",
    "\n",
    "\n",
    "pd.DataFrame(attention_vector, columns=['attention (%)']).plot(kind='bar',\n",
    "                                                               title='Attention Mechanism as '\n",
    "                                                                     'a function of input'\n",
    "                                                                     ' dimensions.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMC]",
   "language": "python",
   "name": "conda-env-AMC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
